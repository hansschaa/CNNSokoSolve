{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "noSolutionDF = pd.read_csv('output_nosol - copia 2.csv')\n",
    "solutionDF = pd.read_csv('output_sol - copia 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n",
      "3\n",
      "3\n",
      "[0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.keras.__version__)\n",
    "noSolutionCount = noSolutionDF.shape[0]\n",
    "solutionCount = solutionDF.shape[0]\n",
    "\n",
    "print(noSolutionCount)\n",
    "print(solutionCount)\n",
    "\n",
    "noSolutionLabel = [0] * noSolutionCount \n",
    "solutionLabel = [1] * solutionCount \n",
    "Y = noSolutionLabel + solutionLabel\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tableros: 6\n"
     ]
    }
   ],
   "source": [
    "boards = []\n",
    "\n",
    "for indice, fila in noSolutionDF.iterrows():\n",
    "    tableros_en_celda = fila['Board'].replace(\"\\r\", \"\").split('\\n')\n",
    "    tableros_en_celda = list(filter(lambda x: x != '', tableros_en_celda))\n",
    "    tablero_matriz = [list(fila) for fila in tableros_en_celda]\n",
    "    boards.append(tablero_matriz)\n",
    "  \n",
    "    \n",
    "\n",
    "for indice, fila in solutionDF.iterrows():\n",
    "    tableros_en_celda = fila['Board'].replace(\"\\r\", \"\").split('\\n')\n",
    "    tableros_en_celda = list(filter(lambda x: x != '', tableros_en_celda))\n",
    "    tablero_matriz = [list(fila) for fila in tableros_en_celda]\n",
    "    boards.append(tablero_matriz)\n",
    "\n",
    "print(\"Total de tableros:\", len(boards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]])]\n"
     ]
    }
   ],
   "source": [
    "def tablero_a_tensor(tablero):\n",
    "    alto = len(tablero)\n",
    "    ancho = len(tablero[0])\n",
    "    tensor = np.zeros((alto, ancho, 7))\n",
    "    for i in range(alto):\n",
    "        for j in range(ancho):\n",
    "            elemento = tablero[i][j]\n",
    "            if elemento == '#':\n",
    "                tensor[i, j, 0] = 1\n",
    "            elif elemento == '$':\n",
    "                tensor[i, j, 1] = 1\n",
    "            elif elemento == '.':\n",
    "                tensor[i, j, 2] = 1\n",
    "            elif elemento == '@':\n",
    "                tensor[i, j, 3] = 1\n",
    "            elif elemento == '*':\n",
    "                tensor[i, j, 4] = 1\n",
    "            elif elemento == '+':\n",
    "                tensor[i, j, 5] = 1\n",
    "            elif elemento == ' ':\n",
    "                tensor[i, j, 6] = 1\n",
    "                \n",
    "    return tensor\n",
    "\n",
    "X = [tablero_a_tensor(tablero) for tablero in boards]\n",
    "\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]]), array([[[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]]])]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.8  \n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train = X[:split_index]\n",
    "Y_train = Y[:split_index]\n",
    "\n",
    "\n",
    "X_val = X[split_index:]\n",
    "Y_val = Y[split_index:]\n",
    "\n",
    "print(X_val)\n",
    "print(Y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, _X, _Y, _name):\n",
    "        'Initialization'\n",
    "        self._X = _X\n",
    "        self._Y = _Y\n",
    "        self._name = _name\n",
    "        self.n_channels = 7\n",
    "        self.n_classes = 2\n",
    "        self.shuffle = True\n",
    "        #self.on_init()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        height_X = np.random.randint(3, 6)\n",
    "        width_X = np.random.randint(3, 6)   \n",
    "        X = np.random.rand(1, height_X, width_X, 7)\n",
    "        Y = np.array([0])\n",
    "\n",
    "        return X, Y\n",
    "        \n",
    "        indexes = random.randint(0, 1)\n",
    "\n",
    "        # Find list of IDs\n",
    "        X = np.array([self._X[indexes]])\n",
    "        Y = np.array([self._Y[indexes]])\n",
    "        print(f\"\\n---------> [{self._name}]__getitem__ Index: {indexes}\")\n",
    "\n",
    "       \n",
    "        if(indexes == 0):\n",
    "            X = np.array([[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "                        \n",
    "                        [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "                        \n",
    "                        [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "                        \n",
    "                        [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "                        \n",
    "                        [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]])\n",
    "        \n",
    "        \n",
    "        elif(indexes == 1):\n",
    "            X = np.array([[[[1, 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "                        [[1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 1., 0., 0., 0.],\n",
    "                        [0., 0., 0., 0., 0., 0., 1.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "                        [[1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 1., 0., 0., 0., 0.],\n",
    "                        [0., 1., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "                        [[1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 0., 0., 0., 1.],\n",
    "                        [0., 0., 0., 0., 0., 0., 1.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "                        [[1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0.]]]])\n",
    "            \n",
    "        print(X)\n",
    "                        \n",
    "\n",
    "        '''height_X = np.random.randint(3, 5 + 1)\n",
    "        width_X = np.random.randint(3, 5 + 1)\n",
    "        X = np.random.rand(1, height_X, width_X, 7)\n",
    "        Y = np.array([0])\n",
    "        height_X = np.random.randint(3, 6)\n",
    "        width_X = np.random.randint(3, 6)\n",
    "        XX = np.random.rand(1, height_X, width_X, 7)\n",
    "        print(f\"-> {XX}\")'''\n",
    "\n",
    "        #y = np.array([0])  # Etiquetas de ejemplo\n",
    "        \n",
    "        #print(self.index)  \n",
    "        #print(y)\n",
    "        \n",
    "\n",
    "        #return X, keras.utils.to_categorical(0, num_classes=2)\n",
    "        return X, Y\n",
    "    \n",
    "    '''def on_init(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        print(f\"---------> [{self._name}] Init\")\n",
    "        self.indexes = np.arange(len(self._X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            print(self.indexes)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"---------> [{self._name}]on_epoch_end\")\n",
    "        self.indexes = np.arange(len(self._X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            print(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_X, list_IDs_Y):\n",
    "        'Generates data containing batch_size samples'\n",
    "        \n",
    "        #print(\"__data_generation\")\n",
    "        #ID = list_IDs_temp[0]\n",
    "        #print(\"ID\")\n",
    "        #print(ID)\n",
    "        X = list_IDs_X[0]\n",
    "        Y = list_IDs_Y[0]\n",
    "      \n",
    "        return X, Y'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element of shape (1, 5, 3, 7) where an element of shape (None, 3, 5, 7) was expected.\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (1, 5, 3, 7) where an element of shape (None, 3, 5, 7) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2413]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#model.summary()\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo usando fit\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Graficar\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m'''plt.figure(figsize=(12, 6))\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mplt.plot(history.history['accuracy'], label='Training Accuracy')\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mplt.legend()\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mplt.show()'''\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element of shape (1, 5, 3, 7) where an element of shape (None, 3, 5, 7) was expected.\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Hans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (1, 5, 3, 7) where an element of shape (None, 3, 5, 7) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2413]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Conv2D, GlobalMaxPooling2D,GlobalAveragePooling2D, Dense, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=23)\n",
    "#print(X_train[0].shape, len(Y_train), len(X_test), len(Y_test))\n",
    "\n",
    "'''X_train = tf.convert_to_tensor(X_train, dtype = tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype = tf.float32)\n",
    "Y_train = tf.convert_to_tensor(Y_train, dtype = tf.float32)\n",
    "Y_test = tf.convert_to_tensor(Y_test, dtype = tf.float32)'''\n",
    "\n",
    "\n",
    "#(height, width, channels, batch)\n",
    "input_shape = (None,None, 7)  \n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Generators\n",
    "train_generator = DataGenerator(X_train, Y_train, \"train\")\n",
    "val_generator = DataGenerator(X_val, Y_val, \"val\")\n",
    "\n",
    "# Arq\n",
    "#dropout\n",
    "#regla para saber cuantos filtros probar\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = Conv2D(filters=64, kernel_size=1, activation='relu', padding='same')(x)\n",
    "# conv2d que transforma todo a x * y * 64\n",
    "x = Conv2D(filters=1, kernel_size=1, activation='relu', padding='same')(x)\n",
    "#Condensa todos los valores de x * y * 1 a un solo valor \n",
    "x = GlobalMaxPooling2D()(x)\n",
    "outputs = Dense(1, activation = \"sigmoid\")(x) # softmax output\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()\n",
    "\n",
    "# Entrenar el modelo usando fit\n",
    "model.fit(train_generator,epochs=2, validation_data= val_generator)\n",
    "\n",
    "# Graficar\n",
    "'''plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
